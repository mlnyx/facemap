#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Willis ì•ˆë©´ ê³„ì¸¡ë²• - ì‚¬ì§„ ë¶„ì„ ë²„ì „
"""

import cv2
import numpy as np
import os
import sys
from PIL import Image as PILImage, ImageDraw, ImageFont

from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from mediapipe import Image, ImageFormat


class PhotoAnalyzer:
    """ì‚¬ì§„ ë¶„ì„ê¸°"""
    
    NOSE_TIP = 2
    CHIN = 152
    MOUTH_TOP = 13
    MOUTH_BOTTOM = 14
    MOUTH_LEFT = 61
    MOUTH_RIGHT = 291
    LEFT_EYE = [33, 133, 160, 159, 158, 157, 173]
    RIGHT_EYE = [362, 263, 387, 386, 385, 384, 398]
    LEFT_FACE = 234
    RIGHT_FACE = 454
    
    NORMAL_MIN = 0.90
    NORMAL_MAX = 1.10
    
    def __init__(self):
        model_path = "face_landmarker.task"
        if not os.path.exists(model_path):
            print("ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            import urllib.request
            url = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
            urllib.request.urlretrieve(url, model_path)
        
        base_options = python.BaseOptions(model_asset_path=model_path)
        options = vision.FaceLandmarkerOptions(
            base_options=base_options,
            num_faces=1,
            min_face_detection_confidence=0.3
        )
        self.detector = vision.FaceLandmarker.create_from_options(options)
        
        # í•œê¸€ í°íŠ¸
        font_paths = [
            "/System/Library/Fonts/Supplemental/AppleGothic.ttf",
            "/System/Library/Fonts/AppleSDGothicNeo.ttc",
            "/Library/Fonts/Arial Unicode.ttf"
        ]
        self.font_path = None
        for path in font_paths:
            if os.path.exists(path):
                self.font_path = path
                break
    
    def detect(self, image):
        """ì–¼êµ´ ê°ì§€"""
        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        mp_image = Image(image_format=ImageFormat.SRGB, data=rgb)
        return self.detector.detect(mp_image)
    
    @staticmethod
    def distance(p1, p2):
        return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)
    
    def get_symmetry(self, landmarks, w, h):
        """ëŒ€ì¹­ë„"""
        left = (landmarks[self.LEFT_FACE].x * w, landmarks[self.LEFT_FACE].y * h)
        right = (landmarks[self.RIGHT_FACE].x * w, landmarks[self.RIGHT_FACE].y * h)
        nose = (landmarks[self.NOSE_TIP].x * w, landmarks[self.NOSE_TIP].y * h)
        
        face_center = (left[0] + right[0]) / 2
        deviation = abs(nose[0] - face_center)
        face_width = self.distance(left, right)
        return max(0, 1 - (deviation / (face_width / 2)))
    
    def get_pupil(self, landmarks, w, h):
        """ë™ê³µ ì¤‘ì‹¬"""
        left_x = np.mean([landmarks[i].x * w for i in self.LEFT_EYE])
        left_y = np.mean([landmarks[i].y * h for i in self.LEFT_EYE])
        right_x = np.mean([landmarks[i].x * w for i in self.RIGHT_EYE])
        right_y = np.mean([landmarks[i].y * h for i in self.RIGHT_EYE])
        return ((left_x + right_x) / 2, (left_y + right_y) / 2)
    
    def get_mouth(self, landmarks, w, h):
        """ì… ì¤‘ì‹¬"""
        x = (landmarks[self.MOUTH_LEFT].x + landmarks[self.MOUTH_RIGHT].x) / 2 * w
        y = (landmarks[self.MOUTH_TOP].y + landmarks[self.MOUTH_BOTTOM].y) / 2 * h
        return (x, y)
    
    def draw_korean(self, image, text, pos, size, color):
        """í•œê¸€ ê·¸ë¦¬ê¸°"""
        pil_img = PILImage.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_img)
        
        if self.font_path:
            font = ImageFont.truetype(self.font_path, size)
        else:
            font = ImageFont.load_default()
        
        rgb_color = (color[2], color[1], color[0])
        draw.text(pos, text, font=font, fill=rgb_color)
        
        return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
    
    def analyze_photo(self, image_path):
        """ì‚¬ì§„ ë¶„ì„"""
        print(f"\nğŸ“· ì‚¬ì§„ ë¶„ì„ ì¤‘: {image_path}")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        if image is None:
            print("âŒ ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        h, w = image.shape[:2]
        result = self.detect(image)
        
        if not result.face_landmarks:
            print("âŒ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        landmarks = result.face_landmarks[0]
        
        # ëœë“œë§ˆí¬ í‘œì‹œ
        for lm in landmarks:
            x, y = int(lm.x * w), int(lm.y * h)
            cv2.circle(image, (x, y), 2, (180, 180, 180), -1)
        
        # ëŒ€ì¹­ë„
        symmetry = self.get_symmetry(landmarks, w, h)
        
        # ì£¼ìš” í¬ì¸íŠ¸
        pupil = self.get_pupil(landmarks, w, h)
        mouth = self.get_mouth(landmarks, w, h)
        nose = (landmarks[self.NOSE_TIP].x * w, landmarks[self.NOSE_TIP].y * h)
        chin = (landmarks[self.CHIN].x * w, landmarks[self.CHIN].y * h)
        
        # ê±°ë¦¬ ê³„ì‚°
        pupil_to_mouth = self.distance(pupil, mouth)
        nose_to_chin = self.distance(nose, chin)
        ratio = nose_to_chin / pupil_to_mouth if pupil_to_mouth > 0 else 0
        
        # íŒì •
        if symmetry < 0.85:
            classification = "âš ï¸ ì •ë©´ì´ ì•„ë‹˜"
            color = (100, 255, 255)
        elif self.NORMAL_MIN <= ratio <= self.NORMAL_MAX:
            classification = "ì •ìƒ"
            color = (80, 200, 120)
        elif ratio < self.NORMAL_MIN:
            classification = "í‰ê·  ì´í•˜ (ìˆ˜ì§ê³ ê²½ ê°ì†Œ)"
            color = (80, 80, 255)
        else:
            classification = "í‰ê·  ì´ìƒ (ìˆ˜ì§ê³ ê²½ ì¦ê°€)"
            color = (80, 165, 255)
        
        # ì¸¡ì •ì„  ê·¸ë¦¬ê¸°
        cv2.line(image, (int(pupil[0]), int(pupil[1])),
                (int(mouth[0]), int(mouth[1])), (255, 200, 100), 4)
        cv2.line(image, (int(nose[0]), int(nose[1])),
                (int(chin[0]), int(chin[1])), (100, 100, 255), 4)
        
        # í¬ì¸íŠ¸
        for pt in [pupil, mouth, nose, chin]:
            cv2.circle(image, (int(pt[0]), int(pt[1])), 8, (255, 255, 255), -1)
            cv2.circle(image, (int(pt[0]), int(pt[1])), 9, (0, 0, 0), 2)
        
        # ì •ë³´ íŒ¨ë„
        overlay = image.copy()
        cv2.rectangle(overlay, (0, 0), (w, 220), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.75, image, 0.25, 0, image)
        
        image = self.draw_korean(image, "Willis ì•ˆë©´ ê³„ì¸¡ë²• ë¶„ì„ ê²°ê³¼", (20, 10), 36, (255, 255, 255))
        image = self.draw_korean(image, f"ë™ê³µ-êµ¬ì—´ ê±°ë¦¬: {pupil_to_mouth:.1f}px", (20, 60), 26, (255, 200, 100))
        image = self.draw_korean(image, f"ë¹„ì €ë¶€-í„±ë ê±°ë¦¬: {nose_to_chin:.1f}px", (20, 100), 26, (100, 100, 255))
        image = self.draw_korean(image, f"Willis ë¹„ìœ¨: {ratio:.3f}", (20, 140), 26, (255, 255, 255))
        image = self.draw_korean(image, "(ì •ìƒ ë²”ìœ„: 0.90 ~ 1.10)", (20, 180), 20, (180, 180, 180))
        
        # íŒì • ê²°ê³¼
        x = w - 400
        cv2.rectangle(image, (x, 20), (w - 20, 90), color, -1)
        cv2.rectangle(image, (x, 20), (w - 20, 90), (255, 255, 255), 4)
        image = self.draw_korean(image, f"íŒì •: {classification}", (x + 15, 35), 28, (255, 255, 255))
        
        # í•˜ë‹¨ ì •ë³´
        image = self.draw_korean(image, f"ëŒ€ì¹­ë„: {symmetry:.1%} | íŒŒë€ì„ : ë™ê³µ-êµ¬ì—´ | ë¹¨ê°„ì„ : ë¹„ì €ë¶€-í„±ë", 
                                (20, h - 40), 20, (255, 255, 255))
        
        # ê²°ê³¼ ì¶œë ¥
        print("=" * 60)
        print(f"ë™ê³µ-êµ¬ì—´ ê±°ë¦¬: {pupil_to_mouth:.1f}px")
        print(f"ë¹„ì €ë¶€-í„±ë ê±°ë¦¬: {nose_to_chin:.1f}px")
        print(f"Willis ë¹„ìœ¨: {ratio:.3f}")
        print(f"ëŒ€ì¹­ë„: {symmetry:.1%}")
        print(f"íŒì •: {classification}")
        print("=" * 60)
        
        # ì €ì¥
        output_path = image_path.rsplit('.', 1)[0] + '_willis_ë¶„ì„.jpg'
        cv2.imwrite(output_path, image)
        print(f"âœ… ê²°ê³¼ ì €ì¥ë¨: {output_path}")
        
        # í™”ë©´ í‘œì‹œ
        cv2.namedWindow('Willis ë¶„ì„ ê²°ê³¼', cv2.WINDOW_NORMAL)
        cv2.imshow('Willis ë¶„ì„ ê²°ê³¼', image)
        print("\nì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        
        return image


def main():
    print("=" * 60)
    print("Willis ì•ˆë©´ ê³„ì¸¡ë²• - ì‚¬ì§„ ë¶„ì„")
    print("=" * 60)
    
    if len(sys.argv) < 2:
        print("\nì‚¬ìš©ë²•:")
        print("  python willis_photo.py <ì´ë¯¸ì§€_íŒŒì¼>")
        print("\nì˜ˆì‹œ:")
        print("  python willis_photo.py photo.jpg")
        print("  python willis_photo.py /Users/name/Desktop/face.png")
        return
    
    image_path = sys.argv[1]
    
    if not os.path.exists(image_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return
    
    analyzer = PhotoAnalyzer()
    analyzer.analyze_photo(image_path)


if __name__ == "__main__":
    main()
